{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "from pyspark.sql.types import StringType, IntegerType, TimestampType, LongType\n",
    "from pyspark.sql.types import ArrayType, FloatType, BooleanType, DateType\n",
    "\n",
    "spark = (SparkSession.builder.appName(\"Data_stats\").getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af07cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate list of column according to datatypes\n",
    "\n",
    "string_columns = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType)]\n",
    "    \n",
    "numeric_columns = [field.name for field in df.schema.fields if isinstance(field.dataType, LongType) or isinstance(field.dataType, IntegerType) or isinstance(field.dataType, DecimalType)]\n",
    "    \n",
    "date_columns = [field.name for field in df.schema.fields if isinstance(field.dataType, TimestampType)]\n",
    "\n",
    "# Find the data types for all columns\n",
    "col_dtype_list = [dict(df.dtypes)]\n",
    "\n",
    "dtype_df = spark.createDataFrame(col_dtype_list)\n",
    "dtype_df = dtype_df.select(lit(\"data_types\").alias(\"summary\"), \"*\")\n",
    "\n",
    "# Count of Null values for all columns\n",
    "\n",
    "null_df = df.select([count(when(col(c).isNull(), c)).alias(c).cast(\"string\") for c in df.columns]) \n",
    "null_df = null_df.select(lit(\"number_of_null_values\").alias(\"summary\"), \"*\")\n",
    "\n",
    "# Row count for all columns\n",
    "\n",
    "row_count_df = df.select([count(when(col(c).isNull() | col(c).isNotNull(), c)).alias(c).cast(\"string\") for c in df.columns])\n",
    "row_count_df = row_count_df.select(lit(\"row_count\").alias(\"summary\"), \"*\")\n",
    "\n",
    "# Percentage of null values\n",
    "\n",
    "null_percentage_df = null_df.join(row_count_df).select([round(null_df[c]*100 / row_count_df[c]).alias(c).cast(\"string\") for c in null_df.columns[1:]])\n",
    "null_percentage_df = null_percentage_df.select(lit(\"percentage_of_null_values\").alias(\"summary\"), \"*\")\n",
    "\n",
    "# Numeric_columns metrics\n",
    "\n",
    "numeric_df = df.select(*numeric_columns).summary(\"min\", \"max\") # max and min values across columns\n",
    "\n",
    "# String_columns metrics\n",
    "\n",
    "string_df_1 = df.select([max(length(c)).alias(c) for c in string_columns]) # max length\n",
    "string_df_1 = string_df_1.select(lit(\"max_length\").alias(\"summary\"), \"*\")\n",
    "\n",
    "string_df_2 = df.select([min(length(c)).alias(c) for c in string_columns]) # min length\n",
    "string_df_2 = string_df_2.select(lit(\"min_length\").alias(\"summary\"), \"*\")\n",
    "\n",
    "string_df_3 = df.select([countDistinct(c).alias(c) for c in string_columns]) # count of categorical values\n",
    "string_df_3 = string_df_3.select(lit(\"number_of_categorical_values\").alias(\"summary\"), \"*\")\n",
    "\n",
    "string_df = string_df_1.union(string_df_2).union(string_df_3)\n",
    "    \n",
    "# Date_columns metrics\n",
    "\n",
    "date_df_1 = df.select([max(c).alias(c).cast(\"string\") for c in date_columns]) # max date\n",
    "date_df_1 = date_df_1.select(lit(\"max_date\").alias(\"summary\"), \"*\")\n",
    "    \n",
    "date_df_2 = df.select([min(c).alias(c).cast(\"string\") for c in date_columns]) # min date\n",
    "date_df_2 = date_df_2.select(lit(\"min_date\").alias(\"summary\"), \"*\")\n",
    "\n",
    "date_df = date_df_1.union(date_df_2)\n",
    "\n",
    "# Add missing columns for string, date, numeric df's - to make all them available for union\n",
    "\n",
    "for column in [column for column in dtype_df.columns if column not in string_df.columns]:\n",
    "    string_df = string_df.withColumn(column, lit(None).cast(\"string\"))\n",
    "\n",
    "for column in [column for column in dtype_df.columns if column not in numeric_df.columns]:\n",
    "    numeric_df = numeric_df.withColumn(column, lit(None).cast(\"string\"))\n",
    "\n",
    "for column in [column for column in dtype_df.columns if column not in date_df.columns]:\n",
    "    date_df = date_df.withColumn(column, lit(None).cast(\"string\"))\n",
    "\n",
    "# Combine all metrics\n",
    "\n",
    "final_df = dtype_df.unionByName(row_count_df).unionByName(null_df).unionByName(null_percentage_df).unionByName(numeric_df).unionByName(string_df).unionByName(date_df)\n",
    "\n",
    "return final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
